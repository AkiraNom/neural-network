{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23614a3b-3de0-4269-b7cf-2ced0e70ed86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99f1742-c9a4-4784-8c8c-9245712f0540",
   "metadata": {},
   "source": [
    "### Backpropagation from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a5e49b-23a1-4f01-bf50-cc88add896df",
   "metadata": {},
   "source": [
    "### Generalized Error Backpropagaition for Any layer\n",
    "\n",
    "$$\\Large\\delta^{[l]}=\\frac{\\partial L}{\\partial Z^{[l]}}=\\frac{\\partial L}{\\partial A^{[l]}}\\odot \\frac{\\partial A}{\\partial Z^{[l]}}=\\delta^{l+1}W^{[l+1]} \\odot \\sigma'(z^{[l]})$$\n",
    "\n",
    "**gradient parameter**\n",
    "$$\\Large\\frac{\\partial L}{\\partial W^{[l]}}=\\delta^{[l]T}A^{[l-1]}$$\n",
    "$$\\Large\\frac{\\partial L}{\\partial b^{[l]}}=\\sum{\\delta^{[l]}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "604ce035-b2cd-4e4d-b9f8-0c4c5aa4b19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_backward(A, W, b, z):\n",
    "    W.grad_ = z.grad_.T @ A\n",
    "    b.grad_ = torch.sum(z.grad_, dim=0)\n",
    "    A.grad_ = z.grad_ @ W \n",
    "\n",
    "def relu_backward(z, A):\n",
    "    z.grad_ = A.grad_ * (z>0).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7467a94c-4f85-453e-8bed-49be79445183",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_cross_entropy(x, y_true):\n",
    "    \n",
    "    e_x = torch.exp(x - torch.max(x, dim=-1, keepdim=True)[0])\n",
    "    softmax_output = e_x / torch.sum(e_x, dim=-1,keepdim=True) + 1e-10\n",
    "    loss = -torch.sum(y_true * torch.log(softmax_output+ 1e-10)) / y_true.shape[0]\n",
    "    \n",
    "    return loss, softmax_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5329c004-eaac-4be2-8c35-43244f13e4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear(X, W, b):\n",
    "    return X@W.T + b\n",
    "\n",
    "def relu(Z):\n",
    "    return Z.clamp_min(0.)\n",
    "def forward_backward(X, y):\n",
    "    # forward\n",
    "    Z1 = linear(X,W1,b1)\n",
    "    Z1.retain_grad()\n",
    "    A1 = relu(Z1)\n",
    "    A1.retain_grad()\n",
    "    Z2 = linear(A1, W2, b2)\n",
    "    Z2.retain_grad()\n",
    "    loss, A2 = softmax_cross_entropy(Z2,y)\n",
    "\n",
    "    # backward\n",
    "    Z2.grad_ = (A2 - y) / X.shape[0]\n",
    "    linear_backward(A1, W2, b2, Z2)\n",
    "    relu_backward(Z1, A1)\n",
    "    linear_backward(X, W1, b1, Z1)\n",
    "\n",
    "    return loss, Z1, A1, Z2, A2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e4a4a3-00ed-429f-9943-4fad49b0303d",
   "metadata": {},
   "source": [
    "### Compare results with Autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "ecfeb7a4-2881-40d3-93d7-c26bac1771db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1437, 8, 8) (1437,)\n",
      "(360, 8, 8) (360,)\n"
     ]
    }
   ],
   "source": [
    "dataset = datasets.load_digits()\n",
    "images = dataset['images']\n",
    "target = dataset['target']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(images,target, test_size=0.2, random_state=42)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "c58dd7ac-2a70-4861-81fe-02623ec28a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing data\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32).reshape(-1,64) \n",
    "y_train = F.one_hot(torch.tensor(y_train), num_classes=10)\n",
    "\n",
    "X_val = torch.tensor(X_val, dtype=torch.float32).reshape(-1,64) \n",
    "y_val = F.one_hot(torch.tensor(y_val), num_classes=10)\n",
    "\n",
    "#normalization \n",
    "X_train_mean = X_train.mean()\n",
    "X_train_std = X_train.std()\n",
    "X_train = (X_train - X_train_mean) / X_train_std\n",
    "X_val = (X_val - X_train_mean) / X_train_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "b928273f-8214-47ab-89d7-b5437ff34283",
   "metadata": {},
   "outputs": [],
   "source": [
    "m, n = X_train.shape\n",
    "\n",
    "nh= 30 # number of hidden layer neurons\n",
    "class_num = 10\n",
    "# W1 = torch.randn((nh, n), requires_grad=True) # output x input\n",
    "W1 = torch.randn((nh, n)) * torch.sqrt(torch.tensor(2./n))\n",
    "W1.requires_grad = True\n",
    "b1 = torch.zeros((1,nh), requires_grad=True) # 1 x nh\n",
    "\n",
    "# W2 = torch.rand((class_num, nh), requires_grad=True)\n",
    "W2 = torch.randn((class_num,nh)) * torch.sqrt(torch.tensor(2./nh))\n",
    "W2.requires_grad = True\n",
    "b2 = torch.zeros((1,class_num), requires_grad=True)\n",
    "loss, Z1, A1, Z2, A2 = forward_backward(X_train, y_train)\n",
    "\n",
    "# autograd\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ef0ed835-80c7-4261-90d3-fedc8f3d27f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False,  True,  True,  ...,  True,  True, False],\n",
       "        [ True,  True,  True,  ...,  True,  True,  True],\n",
       "        [ True, False, False,  ..., False, False, False],\n",
       "        ...,\n",
       "        [False,  True,  True,  ..., False,  True,  True],\n",
       "        [False,  True, False,  ..., False, False,  True],\n",
       "        [ True, False,  True,  ...,  True,  True,  True]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z2.grad == Z2.grad_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26b1e46-ba81-4776-8972-d4eaa8defc02",
   "metadata": {},
   "source": [
    "Not all of gradients have the same value. This is due to large values in Z2. Inputing such large values into a softmax function returns unstable values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "01f86e96-74b7-4d8e-8529-a2f557d13a5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[6.6815e-01, 1.9412e-01, 4.6190e-01,  ..., 6.7576e-02, 3.4622e-02,\n",
       "         4.0804e-01],\n",
       "        [4.6283e-01, 3.8033e-01, 1.6008e+00,  ..., 1.2597e+00, 1.8649e+00,\n",
       "         1.6783e+00],\n",
       "        [4.6138e+01, 3.4990e+01, 3.2816e+01,  ..., 4.1303e+01, 3.8437e+01,\n",
       "         4.4803e+01],\n",
       "        ...,\n",
       "        [5.2852e+01, 3.9986e+01, 3.6280e+01,  ..., 4.5761e+01, 4.2238e+01,\n",
       "         5.1130e+01],\n",
       "        [1.9658e+01, 1.6038e+01, 1.2339e+01,  ..., 1.6186e+01, 1.5451e+01,\n",
       "         2.2926e+01],\n",
       "        [1.9925e+00, 1.0710e+00, 1.1298e+00,  ..., 1.7635e+00, 1.5072e+00,\n",
       "         2.8835e+00]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a4aa6f33-c289-4f92-b000-4ceed90ff1a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.8119, -0.8119, -0.3139,  ...,  1.3459, -0.1479, -0.8119],\n",
       "        [-0.8119, -0.8119,  0.6820,  ..., -0.3139, -0.8119, -0.8119],\n",
       "        [-0.8119, -0.8119, -0.8119,  ...,  0.1840, -0.8119, -0.8119],\n",
       "        ...,\n",
       "        [-0.8119, -0.8119,  0.6820,  ...,  1.8439, -0.4799, -0.8119],\n",
       "        [-0.8119, -0.8119, -0.6459,  ..., -0.8119, -0.8119, -0.8119],\n",
       "        [-0.8119, -0.8119, -0.6459,  ..., -0.6459, -0.8119, -0.8119]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "88ab030f-7737-49b7-95c0-4aabbf56de0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.2345, -3.5868, -3.8859,  ...,  0.6438, -3.0002, -2.8253],\n",
       "        [-3.7590, -0.9433, -3.6602,  ..., -1.2557, -2.1354, -3.8087],\n",
       "        [ 0.7664,  4.8794,  1.5471,  ...,  2.7545,  2.0620, -0.2536],\n",
       "        ...,\n",
       "        [ 3.3619,  6.3161,  1.6896,  ...,  3.6176,  0.7358,  2.4133],\n",
       "        [-0.1012,  5.5298, -1.2030,  ..., -0.4551, -3.1179, -1.3277],\n",
       "        [-3.0476, -1.6174, -3.3693,  ..., -3.1016, -3.8619, -1.7228]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3bd5d9-5f18-460c-840c-b8903f02624f",
   "metadata": {},
   "source": [
    "X_train is normalized to avoid having such large values. Z1 still looks ok. However, since $Z2 = Z1 * W2 + b$, Z2 significantlly grows as you increase layers. This is one of issues in NN. <br>\n",
    "<br>\n",
    "W1 is taken from a normal distribution ($W1 \\sim N(0,1)$) of mean=0, std=1<br> \n",
    "Instead, taking an initial parameter from this normal distribution $W1 \\sim N(0,2/n)$ avoids this issue.\n",
    "\n",
    "```python\n",
    "# W1 = torch.randn((nh, n), requires_grad=True) # output x input\n",
    "W1 = torch.randn((nh, n)) * torch.sqrt(torch.tensor(2./n))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a29d5358-fb5a-431d-9b08-68e262853209",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0458, -0.0440, -0.0186,  ...,  0.0508,  0.0143, -0.0304],\n",
       "        [-0.0105, -0.0105, -0.0082,  ...,  0.0070, -0.0071, -0.0095],\n",
       "        [-0.0308, -0.0316, -0.0142,  ..., -0.0055, -0.0214, -0.0326],\n",
       "        ...,\n",
       "        [-0.0306, -0.0224,  0.0397,  ...,  0.0210,  0.0082, -0.0238],\n",
       "        [ 0.0119,  0.0094, -0.0090,  ..., -0.0175, -0.0016,  0.0023],\n",
       "        [ 0.0109,  0.0103, -0.0031,  ...,  0.0042,  0.0102,  0.0105]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W1.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "436df897-1e67-41c7-897e-26479f05dc90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0458, -0.0440, -0.0186,  ...,  0.0508,  0.0143, -0.0304],\n",
       "        [-0.0105, -0.0105, -0.0082,  ...,  0.0070, -0.0071, -0.0095],\n",
       "        [-0.0308, -0.0316, -0.0142,  ..., -0.0055, -0.0214, -0.0326],\n",
       "        ...,\n",
       "        [-0.0306, -0.0224,  0.0397,  ...,  0.0210,  0.0082, -0.0238],\n",
       "        [ 0.0119,  0.0094, -0.0090,  ..., -0.0175, -0.0016,  0.0023],\n",
       "        [ 0.0109,  0.0103, -0.0031,  ...,  0.0042,  0.0102,  0.0105]],\n",
       "       grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W1.grad_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80031cbc-7eff-4f0d-8a1c-f357563a93fd",
   "metadata": {},
   "source": [
    "#### check if gradient from scratch is similar to gradients from autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3334d450-7f12-4d2c-9b6b-01d5facd348b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1: True\n",
      "b1: True\n",
      "W2: True\n",
      "b2: True\n"
     ]
    }
   ],
   "source": [
    "print(f'W1: {torch.allclose(W1.grad, W1.grad_)}')\n",
    "print(f'b1: {torch.allclose(b1.grad, b1.grad_)}')\n",
    "print(f'W2: {torch.allclose(W2.grad, W2.grad_)}')\n",
    "print(f'b2: {torch.allclose(b2.grad, b2.grad_)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f7dc5f-85f3-42e7-ae86-544776f8cc6a",
   "metadata": {},
   "source": [
    "### Integrate backpropagation with MLP\n",
    "\n",
    "Using a learning loop developed during multiclass logistic regression model in multiclass_Logistic_Regression.ipynb,\n",
    "integragte a MLP model and backpropagation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "89e30ba3-9812-4b22-829a-e5932bd3f767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1: train loss :2.0919 val loss: 1.3614 val accuracy 0.6028\n",
      "epoch: 2: train loss :1.0869 val loss: 0.8210 val accuracy 0.8306\n",
      "epoch: 3: train loss :0.6866 val loss: 0.5577 val accuracy 0.8750\n",
      "epoch: 4: train loss :0.4985 val loss: 0.4216 val accuracy 0.8944\n",
      "epoch: 5: train loss :0.3954 val loss: 0.3439 val accuracy 0.9111\n",
      "epoch: 6: train loss :0.3288 val loss: 0.2883 val accuracy 0.9306\n",
      "epoch: 7: train loss :0.2841 val loss: 0.2550 val accuracy 0.9278\n",
      "epoch: 8: train loss :0.2501 val loss: 0.2286 val accuracy 0.9472\n",
      "epoch: 9: train loss :0.2249 val loss: 0.2057 val accuracy 0.9472\n",
      "epoch: 10: train loss :0.2050 val loss: 0.1890 val accuracy 0.9528\n",
      "epoch: 11: train loss :0.1880 val loss: 0.1758 val accuracy 0.9500\n",
      "epoch: 12: train loss :0.1739 val loss: 0.1657 val accuracy 0.9556\n",
      "epoch: 13: train loss :0.1621 val loss: 0.1578 val accuracy 0.9528\n",
      "epoch: 14: train loss :0.1515 val loss: 0.1471 val accuracy 0.9583\n",
      "epoch: 15: train loss :0.1417 val loss: 0.1437 val accuracy 0.9639\n",
      "epoch: 16: train loss :0.1350 val loss: 0.1375 val accuracy 0.9667\n",
      "epoch: 17: train loss :0.1280 val loss: 0.1322 val accuracy 0.9611\n",
      "epoch: 18: train loss :0.1218 val loss: 0.1271 val accuracy 0.9694\n",
      "epoch: 19: train loss :0.1167 val loss: 0.1226 val accuracy 0.9639\n",
      "epoch: 20: train loss :0.1113 val loss: 0.1190 val accuracy 0.9667\n",
      "epoch: 21: train loss :0.1068 val loss: 0.1149 val accuracy 0.9639\n",
      "epoch: 22: train loss :0.1026 val loss: 0.1130 val accuracy 0.9667\n",
      "epoch: 23: train loss :0.0984 val loss: 0.1113 val accuracy 0.9639\n",
      "epoch: 24: train loss :0.0951 val loss: 0.1076 val accuracy 0.9722\n",
      "epoch: 25: train loss :0.0910 val loss: 0.1068 val accuracy 0.9722\n",
      "epoch: 26: train loss :0.0882 val loss: 0.1037 val accuracy 0.9722\n",
      "epoch: 27: train loss :0.0854 val loss: 0.1016 val accuracy 0.9722\n",
      "epoch: 28: train loss :0.0823 val loss: 0.1003 val accuracy 0.9694\n",
      "epoch: 29: train loss :0.0798 val loss: 0.0988 val accuracy 0.9694\n",
      "epoch: 30: train loss :0.0770 val loss: 0.0980 val accuracy 0.9722\n"
     ]
    }
   ],
   "source": [
    "epochs = 30\n",
    "batch_size = 30\n",
    "num_batches = np.ceil(len(y_train)/batch_size).astype(int)\n",
    "loss_log = []\n",
    "learning_rate = 0.03\n",
    "\n",
    "# logs\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "val_accuracies = []\n",
    "\n",
    "# initiallize parameters\n",
    "m, n = X_train.shape\n",
    "\n",
    "nh= 30 # number of hidden layer neurons\n",
    "class_num = 10\n",
    "\n",
    "W1 = torch.randn((nh, n)) * torch.sqrt(torch.tensor(2./n))\n",
    "W1.requires_grad = True\n",
    "b1 = torch.zeros((1,nh), requires_grad=True) # 1 x nh\n",
    "\n",
    "W2 = torch.randn((class_num,nh)) * torch.sqrt(torch.tensor(2./nh))\n",
    "W2.requires_grad = True\n",
    "b2 = torch.zeros((1,class_num), requires_grad=True)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    shuffled_indices = np.random.permutation(len(y_train))\n",
    "    running_loss = 0\n",
    "    \n",
    "    for i in range(num_batches):\n",
    "\n",
    "        start = i * batch_size\n",
    "        end = start + batch_size\n",
    "        batch_indices = shuffled_indices[start:end]\n",
    "\n",
    "        # place break point\n",
    "        # import pdb; pdb.set_trace()\n",
    "        \n",
    "        y_true = y_train[batch_indices,:] # data_num x class_num.\n",
    "        X_train_ = X_train[batch_indices,:] # data_num x feature_num\n",
    "\n",
    "        # forward\n",
    "        Z1 = linear(X_train_,W1,b1)\n",
    "        Z1.retain_grad()\n",
    "        A1 = relu(Z1)\n",
    "        A1.retain_grad()\n",
    "        Z2 = linear(A1, W2, b2)\n",
    "        Z2.retain_grad()\n",
    "        loss, A2 = softmax_cross_entropy(Z2,y_true)\n",
    "        \n",
    "        loss_log.append(loss.item())\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # backward\n",
    "        Z2.grad_ = (A2 - y_true) / X_train_.shape[0]\n",
    "        linear_backward(A1, W2, b2, Z2)\n",
    "        relu_backward(Z1, A1)\n",
    "        linear_backward(X_train_, W1, b1, Z1)\n",
    "\n",
    "        # update parameter\n",
    "        with torch.no_grad():\n",
    "            W1 -= learning_rate * W1.grad_\n",
    "            b1 -= learning_rate * b1.grad_\n",
    "            W2 -= learning_rate * W2.grad_\n",
    "            b2 -= learning_rate * b2.grad_\n",
    "\n",
    "        # initialize gradient\n",
    "        W1.grad_ = None\n",
    "        b1.grad_ = None\n",
    "        W2.grad_ = None\n",
    "        b2.grad_ = None\n",
    "\n",
    "    # validation\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        Z1_val = linear(X_val,W1,b1)\n",
    "        A1_val = relu(Z1_val)\n",
    "        Z2_val = linear(A1_val, W2, b2)\n",
    "\n",
    "        val_loss, A2 = softmax_cross_entropy(Z2_val, y_val)\n",
    "        val_accuracy = (torch.sum(torch.argmax(A2, dim=-1) == torch.argmax(y_val, dim=-1)) / y_val.shape[0])\n",
    "\n",
    "    train_losses.append(running_loss/num_batches)\n",
    "    val_losses.append(val_loss.item())\n",
    "    val_accuracies.append(val_accuracy.item())\n",
    "\n",
    "    #print log\n",
    "    print(f'epoch: {epoch+1}: train loss :{running_loss/num_batches:.4f} val loss: {val_loss:.4f} val accuracy {val_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "b92673a1-edcb-40c9-b50f-c646e87ae6f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f14cd5f8f10>]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_losses)\n",
    "plt.plot(val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef57202-2fff-4151-9a3a-857afd0e6be4",
   "metadata": {},
   "source": [
    "### Regression model\n",
    "\n",
    "In the preveious section, the model is created for solving a classification problem. In this section, modify the model for a regression prediction. \n",
    "\n",
    "Demonstration purpose:\n",
    "* use mnist dataset\n",
    "* predict a class number\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "5139fd2f-4363-41ad-93fc-247919b775df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(X, y):\n",
    "    return ((X[:,0] - y)**2).mean()\n",
    "\n",
    "def forward_backward(X, y):\n",
    "    # forward\n",
    "    Z1 = linear(X,W1,b1)\n",
    "    Z1.retain_grad()\n",
    "    A1 = relu(Z1)\n",
    "    A1.retain_grad()\n",
    "    Z2 = linear(A1, W2, b2)\n",
    "    Z2.retain_grad()\n",
    "    print(Z2.shape)\n",
    "    loss = mse(Z2, y)\n",
    "\n",
    "    # backward\n",
    "    Z2.grad_ = 2* (Z2 - y.unsqueeze(dim=-1)) / X.shape[0]\n",
    "    linear_backward(A1, W2, b2, Z2)\n",
    "    relu_backward(Z1, A1)\n",
    "    linear_backward(X, W1, b1, Z1)\n",
    "\n",
    "    return loss, Z1, A1, Z2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "d75bc954-389f-47f5-96d5-3c480899c730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1437, 1])\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "y_train_reg = torch.argmax(y_train,dim=-1)\n",
    "\n",
    "y_train_reg.shape\n",
    "\n",
    "# initialize parameter\n",
    "m, n = X_train.shape\n",
    "\n",
    "nh= 30 # number of hidden layer neurons\n",
    "W1 = torch.randn((nh, n), requires_grad=True)\n",
    "b1 = torch.zeros((1, nh), requires_grad=True) # 1 x nh\n",
    "\n",
    "W2 = torch.randn((1,nh), requires_grad=True)\n",
    "b2 = torch.zeros((1,1), requires_grad=True)\n",
    "\n",
    "loss, Z1, A1, Z2 = forward_backward(X_train, y_train_reg)\n",
    "loss.backward()\n",
    "\n",
    "print(torch.allclose(W1.grad_, W1.grad))\n",
    "print(torch.allclose(b1.grad_, b1.grad))\n",
    "print(torch.allclose(W2.grad_, W2.grad))\n",
    "print(torch.allclose(b2.grad_, b2.grad))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb2acc9-8379-4d97-8ccc-16f23e4e1417",
   "metadata": {},
   "source": [
    "### Refactoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "ba457ff4-d3a6-4c96-8c2b-52a19ea2b0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear():\n",
    "    def __init__(self, in_features, out_features):\n",
    "        self.W = torch.randn((out_features, in_features)*torch.sqrt(torch.tensor(2.0/in_featires)))\n",
    "        self.W.requires_grad = True\n",
    "        self.b = torch.zeros((1, out_features), requires_grad=True)\n",
    "        \n",
    "    def forward(X):\n",
    "        self.X = X\n",
    "        self.Z = X@W.T + b\n",
    "        return self.Z\n",
    "        \n",
    "    def backward(self, Z):\n",
    "        self.W.grad_ = Z.grad_.T @ self.X\n",
    "        self.b.grad_ = torch.sum(Z.grad_, dim=0)  \n",
    "        self.X.grad_ = Z.grad_ \n",
    "        return self.X.grad_\n",
    "\n",
    "class Relu():\n",
    "    def forward(self,X):\n",
    "        self.X = X\n",
    "        return X.clamp_min(0.)\n",
    "        \n",
    "    def backward(self,A):\n",
    "        return A.grad_ * (self.X > 0).float()\n",
    "\n",
    "class SoftmaxCrossEntropy():\n",
    "    def forward(self, X, y):\n",
    "        e_x = torch.exp(X - torch.max(X, dim=-1, keepdim=True)[0])\n",
    "        self.softmax_output = e_x / torch.sum(e_x, dim=-1,keepdim=True) + 1e-10\n",
    "        \n",
    "        log_probs = torch.log(self.softmax_output + 1e-10) \n",
    "        target_log_probs = y * log_probs\n",
    "        \n",
    "        self.loss = -target_log_probs.sum(dim=1).mean()\n",
    "\n",
    "        return self.loss\n",
    "\n",
    "    def backward(self, y):\n",
    "        return (self.softmaxt_out - y)/ y.shape[0]\n",
    "        \n",
    "\n",
    "class Model():\n",
    "    def __init__(self, input_features, hidden_units, output_units):\n",
    "        self.linear1 = Linear(input_features, hidden_units)\n",
    "        self.relu = ReLU()\n",
    "        self.linear2 = Linear(hidden_units, output_units)\n",
    "        self.loss_fn = SoftmaxCrossEntropy()\n",
    "        \n",
    "    def forward(self,X,y):\n",
    "        self.X = X\n",
    "        self.Z = self.linear1.forward(X)\n",
    "        self.A1 = self.relu.forward(self.Z)\n",
    "        self.Z2 = self.linear2.forward(self.A1)\n",
    "        \n",
    "        self.loss = self.loss_fn.forward(Z2, y)\n",
    "        return self.loss, self.Z2\n",
    "\n",
    "    def backward(self, y):\n",
    "\n",
    "        self.Z2.grad_ = self.loss_fn.backward(y)\n",
    "        self.A1.grad_ = self.linear2.backward(self.Z2)\n",
    "        self.Z1.grad_ = self.relu.backward(self.A1)\n",
    "        self.X.grad_ = self.linear1.backward(self.Z1)\n",
    "\n",
    "    def zero_grad(self):\n",
    "        # initialize grad\n",
    "        self.linear1.W.grad_ = None\n",
    "        self.linear1.b.grad_ = None\n",
    "        self.linear2.W.grad_ = None\n",
    "        self.linear2.b.grad_ = None\n",
    "\n",
    "    def step(self, learning_rate):\n",
    "        # update grad\n",
    "        self.linear1.W -=  learning_rate * self.linear1.W.grad_\n",
    "        self.linear1.b -=  learning_rate * self.linear1.b.grad_\n",
    "        self.linear2.W -=  learning_rate * self.linear1.W.grad_\n",
    "        self.linear2.b -=  learning_rate * self.linear2.b.grad_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd5bca5-0f9b-49f2-9adc-26023a067d6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
