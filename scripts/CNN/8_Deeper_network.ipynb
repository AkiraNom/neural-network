{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54c492ea-b547-43d0-944e-8133f966d5db",
   "metadata": {},
   "source": [
    "## Deeper Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1abef3af-455b-4a5f-b09b-ca96e5936ce8",
   "metadata": {},
   "source": [
    "### Skip Connection\n",
    "\n",
    "**Degradation problem**\n",
    "While training deep neural nets, the performance of the model drops down with the increase in depth of the architecture. This could be due to overfitting or vanishing/exploding gradients.\n",
    "\n",
    "**skip connections**\n",
    " IT skips some layer in neural network and feeds the output of one layer as the input ot the next layers. \n",
    "\n",
    "<img src=\"./rsc/skip_connection.png\" width=\"600\" height=\"800\">\n",
    "\n",
    "There are two fundamental ways to use skip connections:\n",
    "* **Addition** as in residual architecture\n",
    "* **Concatenation** as in densely connected architecture\n",
    "\n",
    "*further reading*\n",
    "*[Skip Connection and Explanation of ResNet](https://chautuankien.medium.com/skip-connection-and-explanation-of-resnet-afabe792346c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2b61c3-46be-42e8-8035-3ad90dccb018",
   "metadata": {},
   "source": [
    "### Residual Block\n",
    "Architecture of normal residual block (left) and pre-activation residual block (right). \n",
    "According to [Identity Mappings in Deep Residual Networks](https://arxiv.org/abs/1603.05027), the pre-activation residual block makes training easier and improves generalization.\n",
    "<img src=\"./rsc/residual_block.png\" width=\"600\" height=\"800\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d7a8f964-3750-48c0-a04c-bed6c43bbff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "2bd7e444-f5e3-4352-9b96-9c6f82c28846",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normal residual block\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1,padding=1):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding, bias=False)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "\n",
    "        if stride !=1 or in_channels!=out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, padding=0, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "    def forward(self, X):\n",
    "        out = F.relu(self.bn1(self.conv1(X)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(X)\n",
    "        out = F.relu(out)\n",
    "\n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "88c9753c-6198-42ed-b3f7-dfbb85d0f170",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 32, 32])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ResidualBlock(3, 64)\n",
    "X = torch.randn((1,3,32,32))\n",
    "Z = model(X)\n",
    "Z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "e25bddf5-cf6a-4601-8d8c-e9287f5ea382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-activated residual block\n",
    "class PreActBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, stride=1):\n",
    "        super().__init__()\n",
    "        self.bn1 = nn.BatchNorm2d(in_ch)\n",
    "        self.conv1 = nn.Conv2d(in_ch, out_ch, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_ch)\n",
    "        self.conv2 = nn.Conv2d(out_ch, out_ch, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "\n",
    "        if stride !=1 or in_ch != out_ch:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_ch, out_ch, kernel_size=1, stride=stride, bias=False)\n",
    "            )\n",
    "    def forward(self, X):\n",
    "        out = self.conv1(F.relu(self.bn1(X)))\n",
    "        out = self.conv2(F.relu(self.bn2(out)))\n",
    "        out += self.shortcut(X)\n",
    "\n",
    "        return out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "71b36a92-6389-4ed0-acf7-67dedb57eec8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 32, 32])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preact = PreActBlock(3, 64,stride=1)\n",
    "X = torch.randn((1,3,32,32))\n",
    "Z = preact(X)\n",
    "Z.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e23ed56-c7ec-439a-851d-e55a8c805bc2",
   "metadata": {},
   "source": [
    "<img src=\"./rsc/normal_convolution2.png\" width=\"600\" height=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f57f3fa-b78c-4e81-b2e3-4268f9be461a",
   "metadata": {},
   "source": [
    "### Pointwise Convolution\n",
    "\n",
    ">Pointwise Convolution is a type of convolution that uses a 1x1 kernel: a kernel that iterates through every single point. This kernel has a depth of however many channels the input image has.\n",
    "\n",
    "Convolution filter modifiy (HxW) size into a specific size with arranging a channel size. On the other hand, pointwise convolution (1x1 convolution) summarizes a size in a channel axis so that you can arange a desired channel size (reduction orexpansion).\n",
    "\n",
    "Normal convolution:<br>\n",
    "\n",
    "Input is a RGB image of size 12x12. A 5x5 convolution process with a stride of 1 and no padding -scalar multiplication with every 25pixels giving out 1 number every time- generates a 8x8 pixel image. Since the image has three channels, instead of 25 pixels, 75 pixels(25pixels * 3 channels) giving out 1 number. \n",
    " \n",
    "<img src=\"./rsc/normal_convolution.png\" width=\"600\" height=\"800\">\n",
    "\n",
    "<img src=\"./rsc/normal_convolution2.png\" width=\"600\" height=\"800\">\n",
    "Depthwise convolution:<br>\n",
    "\n",
    "Input is a RGB image of size 12x12. A 5x5x1 convolution process with a stride of 1 and no padding -scalar multiplication with every 25pixels giving out 1 number every time- generates a 8x8 pixel per channel -> a 8x8x3 image.\n",
    "\n",
    "<img src=\"./rsc/depthwise_convolution.png\" width=\"600\" height=\"800\">\n",
    "\n",
    "Pointwise convolution - reduction:<br>\n",
    "\n",
    "Pointwise convolution uses a 1x1 kernel. Input is a RGB image of size 8x8. This pointwise convolution -sclar multiplication with 1x1pixel multiplied by channel numbers, 3, giving out 1 number <br>\n",
    "\n",
    "<img src=\"./rsc/pointwise_convolution.png\" width=\"600\" height=\"800\">\n",
    "\n",
    "Pointwise convolution - expansion: <br>\n",
    "\n",
    "Use 256 1x1x3 kernels that output a 8x8x1 image each to get a final image of shape 8x8x256.\n",
    "\n",
    "<img src=\"./rsc/pointwise_convolution2.png\" width=\"600\" height=\"800\">\n",
    "\n",
    "**Advantage**:\n",
    "* **Reduced computational load**\n",
    "* **Paramter Efficiency**\n",
    "* **Preserving Spatial Information**\n",
    "\n",
    "*further reading*:\n",
    "* [A Basic Introduction to Separable Convolutions](https://towardsdatascience.com/a-basic-introduction-to-separable-convolutions-b99ec3102728n)\n",
    "* [Exploring Pointwise Convolution in CNNs: Replacing Fully Connected Layers](https://www.analyticsvidhya.com/blog/2023/11/exploring-pointwise-convolution-in-cnns-replacing-fully-connected-layers/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f46813f-f846-4996-9548-a7ad1e5af693",
   "metadata": {},
   "source": [
    "### Bottleneck\n",
    "\n",
    "<img src=\"./rsc/bottleneck.png\" width=\"300\" height=\"400\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "3bdf647e-29e0-4637-9994-9d33c751b884",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bottleneck(nn.Module):\n",
    "    \n",
    "    def __init__(self,in_ch, out_ch, stride=1):\n",
    "        super().__init__()\n",
    "        self.expansion_factor = 4\n",
    "        self.conv1 = nn.Conv2d(in_ch, out_ch, kernel_size=1,stride=1, padding=0, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_ch)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(out_ch, out_ch, kernel_size=3,stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_ch)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(out_ch, out_ch*self.expansion_factor, kernel_size=1,stride=1, padding=0, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(out_ch*self.expansion_factor)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "\n",
    "        if stride !=1 or in_ch!=out_ch*self.expansion_factor:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_ch, out_ch*self.expansion_factor, kernel_size=1,stride=stride),\n",
    "                nn.BatchNorm2d(out_ch*self.expansion_factor)\n",
    "            )\n",
    "    def forward(self,X):\n",
    "        out = F.relu(self.bn1(self.conv1(X)))\n",
    "        out = F.relu(self.bn2(self.conv2(out)))\n",
    "        out = self.bn3(self.conv3(out))\n",
    "        out += self.shortcut(X)\n",
    "        out = F.relu(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "5fd4aca2-bc25-4b38-845a-9c18ecea04fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 256, 32, 32])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Bottleneck(256, 64,stride=1)\n",
    "X = torch.randn((1,256,32,32))\n",
    "Z = model(X)\n",
    "Z.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21956c8b-5fe3-45d1-b696-3071d77f797c",
   "metadata": {},
   "source": [
    "### ResNet Architecture\n",
    "\n",
    "Residual blocks (commonly pre-activated residual blocks) are the main components of Residual network. ResNet is made by stacking these residual blocks together. \n",
    "\n",
    "ResNet-34 architecture:\n",
    "<img src='./rsc/ResNet.png' width=\"600\" height=\"800\" title=\"ResNET\">\n",
    "\n",
    "Variants of ResNet are ResNet-18, ResNet-50, ResNet-101, ResNet-152 etc. ResNet which has more than 50 layers uses Bottleneck structure. \n",
    "\n",
    "*further reading*\n",
    "* [Understanding ResNet Architecture: A Deep Dive into Residual Neural Network](https://medium.com/@ibtedaazeem/understanding-resnet-architecture-a-deep-dive-into-residual-neural-network-2c792e6537a9)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf79c39-e9e0-4a26-bc02-bc608d82cf4e",
   "metadata": {},
   "source": [
    "### Inception"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e1692c-86f4-4097-b256-624ad21581a0",
   "metadata": {},
   "source": [
    "Inception layer is a combination of 1x1 convolutional layer, 3x3 convolutional layaer, and 5x5 convolutional layer with 1x1 convolution layer for dimensionality reduction and a max pooling layer, giving out one output..\n",
    "\n",
    "\n",
    "<img src=\"./rsc/inception.png\" width=\"600\" height=\"800\">\n",
    "\n",
    "image from [Going Deeper with Convolution](https://arxiv.org/abs/1409.4842) by C. Szegedy. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332b5823-73bc-4a45-960d-f67ef8c977ce",
   "metadata": {},
   "source": [
    "##### scratch development of Inception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "56326b47-dbdf-471d-be53-83bc100d22cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Inception(nn.Module):\n",
    "\n",
    "    def __init__(self, in_ch, out_ch1, out_ch2, out_ch3, out_ch_pool):\n",
    "        super().__init__()\n",
    "\n",
    "        # 1x1 conv\n",
    "        self.bn1 = nn.BatchNorm2d(in_ch)\n",
    "        self.conv1 = nn.Conv2d(in_ch, out_ch1, kernel_size=1, stride=1)\n",
    "\n",
    "        # 1x1 pointwise\n",
    "        self.bn2 = nn.BatchNorm2d(in_ch)\n",
    "        self.conv2 = nn.Conv2d(in_ch, out_ch2, kernel_size=1,stride=1, padding=0, bias=False)\n",
    "        # 3x3 conv\n",
    "        self.bn3 = nn.BatchNorm2d(out_ch2)\n",
    "        self.conv3 = nn.Conv2d(out_ch2, out_ch2, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        # 1x1 pointwise\n",
    "        self.bn4 = nn.BatchNorm2d(in_ch)\n",
    "        self.conv4 = nn.Conv2d(in_ch, out_ch3, kernel_size=1,stride=1, padding=0, bias=False)\n",
    "        # 5x5 conv\n",
    "        self.bn5 = nn.BatchNorm2d(out_ch3)\n",
    "        self.conv5 = nn.Conv2d(out_ch3, out_ch3, kernel_size=5, stride=1, padding=2)\n",
    "\n",
    "        # maxpoo with 3x3\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=1, padding=1)\n",
    "        self.bn6 = nn.BatchNorm2d(in_ch)\n",
    "        self.conv6 = nn.Conv2d(in_ch, out_ch_pool, kernel_size=1,stride=1, padding=0, bias=False)\n",
    "\n",
    "    def forward(self, X):\n",
    "\n",
    "        # 1x1\n",
    "        out1 = self.conv1(F.relu(self.bn1(X)))\n",
    "        \n",
    "        # 3x3\n",
    "        out2 = self.conv2(F.relu(self.bn2(X)))\n",
    "        out2 = self.conv3(F.relu(self.bn3(out2)))\n",
    "        \n",
    "        # 5x5\n",
    "        out3 = self.conv4(F.relu(self.bn4(X)))\n",
    "        out3 = self.conv5(F.relu(self.bn5(out3)))\n",
    "\n",
    "        # maxpool\n",
    "        out4 = self.maxpool(X)        \n",
    "        out4 = self.conv6(F.relu(self.bn6(out4)))\n",
    "\n",
    "        x = torch.cat([out1, out2, out3, out4], dim=1)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "01a04acc-5b75-48c1-b91c-b8d0d502789b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using nn.Sequential improves readability\n",
    "class InceptionModule(nn.Module):\n",
    "\n",
    "    def __init__(self, in_ch, out_ch1, out_ch3, out_ch5, out_ch_pool):\n",
    "        super().__init__()\n",
    "\n",
    "        # 1x1\n",
    "        self.branch1 = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch1, kernel_size=1),\n",
    "            nn.BatchNorm2d(out_ch1),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        # 3x3\n",
    "        self.branch2 = nn.Sequential(\n",
    "            # pointwise\n",
    "            nn.Conv2d(in_ch, out_ch3, kernel_size=1),\n",
    "            nn.BatchNorm2d(out_ch3),\n",
    "            nn.ReLU(),\n",
    "            # 3x3 conv\n",
    "            nn.Conv2d(out_ch3, out_ch3, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch3),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        # 5x5\n",
    "        self.branch3 = nn.Sequential(\n",
    "            # pointwise\n",
    "            nn.Conv2d(in_ch, out_ch5, kernel_size=1),\n",
    "            nn.BatchNorm2d(out_ch5),\n",
    "            nn.ReLU(),\n",
    "            # 5x5 conv\n",
    "            nn.Conv2d(out_ch5, out_ch5, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm2d(out_ch5),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        # Max pooling\n",
    "        self.branch4 = nn.Sequential(\n",
    "            nn.MaxPool2d(kernel_size=3, stride=1, padding=1),\n",
    "            nn.Conv2d(in_ch, out_ch_pool, kernel_size=1),\n",
    "            nn.BatchNorm2d(out_ch_pool),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "    def forward(self, X):\n",
    "        branch1 = self.branch1(X)\n",
    "        branch2 = self.branch2(X)\n",
    "        branch3 = self.branch3(X)\n",
    "        branch4 = self.branch4(X)\n",
    "\n",
    "        return torch.cat([branch1, branch2, branch3, branch4], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "bbc4bdd3-49e0-4d9e-b811-fe0c7503b913",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 256, 28, 28])"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inception = Inception(192, 64, 128, 32, 32)\n",
    "X = torch.randn((16,192, 28,28))\n",
    "Z = inception(X)\n",
    "Z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "286ee3c8-61d4-42f3-9376-9db44b53f267",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 256, 28, 28])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inception = InceptionModule(192, 64, 128, 32, 32)\n",
    "X = torch.randn((16,192, 28,28))\n",
    "Z = inception(X)\n",
    "Z.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4378035c-2c67-4989-9b21-c8991ebdda39",
   "metadata": {},
   "source": [
    "### Depthwise Separable Convolution\n",
    "\n",
    "Depthwise separable convolution is a combination of depthwise colution and pointwise convolution. \n",
    "\n",
    "These type of CNN's are widely used becauses of\n",
    "* lesser number of parameters which reduces overfitting\n",
    "* fewer parameters reduces computational cost\n",
    "  \n",
    "<img src=\"./rsc/normal_depthwise_convolution.png\" width=\"600\" height=\"800\">\n",
    "\n",
    "Some important applications of these type of CNNS's are MobileNet and Xception\n",
    "\n",
    "*further reading*:\n",
    "* [Depth wise Separable Convolutional Neural Networks](https://www.geeksforgeeks.org/depth-wise-separable-convolutional-neural-networks/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e346f28c-09be-4999-85e5-3352257db711",
   "metadata": {},
   "source": [
    "#### Operation cost\n",
    "\n",
    "$$\\text{Total number of parameters} = \\text{Input (C,H,W)} * \\text{Filter (H,W)} * \\text{Output channels} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922cfa5f-b36e-44d3-bd29-1db1fd35a05e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
