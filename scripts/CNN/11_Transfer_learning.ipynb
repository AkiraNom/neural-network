{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "43fc5af6-9d66-4f75-8d58-bc4b4d53543a",
      "metadata": {
        "id": "43fc5af6-9d66-4f75-8d58-bc4b4d53543a"
      },
      "source": [
        "## Transfer Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5a7e1324-f746-48df-a606-8e258760a993",
      "metadata": {
        "id": "5a7e1324-f746-48df-a606-8e258760a993"
      },
      "source": [
        "**What is transfer Learning**\n",
        "\n",
        "Transfer learning is the reuse of a pre-trained model on a new problem. In transfer learning, a machine exploits the knowledge gained from a previous task to improve generalization about another. For example, in training a classifier to predict whether an image contains food, you could use the knowledge it gained during training to recognize drinks.\n",
        "\n",
        "The `torchvision.models` subpackage contains definitions of models for addressing different tasks, including: image classification, pixelwise semantic segmentation, object detection, instance segmentation, person keypoint detection, video classification, and optical flow.\n",
        "\n",
        "[Models and pre-trained weights](https://pytorch.org/vision/stable/models.html)\n",
        "\n",
        "*further reading*:\n",
        "* [A Gentle Introduction to Transfer Learning for Deep Learning](https://machinelearningmastery.com/transfer-learning-for-deep-learning/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "0dd00fed-8eaf-439e-9af8-092935185b4f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0dd00fed-8eaf-439e-9af8-092935185b4f",
        "outputId": "b0d9f333-1f0c-4c89-8c64-823541dab62b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch.nn import functional as F\n",
        "import torchvision.models as models\n",
        "from torchvision.models import ResNet18_Weights\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torch.utils.data import DataLoader\n",
        "from torch import optim, nn\n",
        "\n",
        "import time\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "import utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "b0b575fb-9624-41e6-9b4b-3395c466ec63",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0b575fb-9624-41e6-9b4b-3395c466ec63",
        "outputId": "f1e9024f-521f-4f6f-a3b6-d39f6b77316e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\" )\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "3b4c2c8a-dee6-463c-af2d-c7fbda207e0b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3b4c2c8a-dee6-463c-af2d-c7fbda207e0b",
        "outputId": "44e3f936-d2cd-40c0-94bc-37972d1001d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 179MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "model = models.resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
        "model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2b70d58-c977-4bc0-bd7d-c3098b45199d",
      "metadata": {
        "id": "b2b70d58-c977-4bc0-bd7d-c3098b45199d"
      },
      "source": [
        "The last fc layer generates 1000 classes. We need to modify this value from 1000 to 10 classes for CIFAR10 data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "6e93724f-f771-4c1a-8b04-035571dff429",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6e93724f-f771-4c1a-8b04-035571dff429",
        "outputId": "2cddff40-916d-4095-81cd-05237dc736fe"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "num_classes = 10\n",
        "model.fc = nn.Linear(in_features=512, out_features=num_classes)\n",
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "5c2e2469-3c2d-4cfe-a50e-ad5575693e84",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5c2e2469-3c2d-4cfe-a50e-ad5575693e84",
        "outputId": "7860fc4b-8480-443b-ffd8-7094f58f8fc3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "conv1.weight torch.Size([64, 3, 7, 7])\n",
            "bn1.weight torch.Size([64])\n",
            "bn1.bias torch.Size([64])\n",
            "layer1.0.conv1.weight torch.Size([64, 64, 3, 3])\n",
            "layer1.0.bn1.weight torch.Size([64])\n",
            "layer1.0.bn1.bias torch.Size([64])\n",
            "layer1.0.conv2.weight torch.Size([64, 64, 3, 3])\n",
            "layer1.0.bn2.weight torch.Size([64])\n",
            "layer1.0.bn2.bias torch.Size([64])\n",
            "layer1.1.conv1.weight torch.Size([64, 64, 3, 3])\n",
            "layer1.1.bn1.weight torch.Size([64])\n",
            "layer1.1.bn1.bias torch.Size([64])\n",
            "layer1.1.conv2.weight torch.Size([64, 64, 3, 3])\n",
            "layer1.1.bn2.weight torch.Size([64])\n",
            "layer1.1.bn2.bias torch.Size([64])\n",
            "layer2.0.conv1.weight torch.Size([128, 64, 3, 3])\n",
            "layer2.0.bn1.weight torch.Size([128])\n",
            "layer2.0.bn1.bias torch.Size([128])\n",
            "layer2.0.conv2.weight torch.Size([128, 128, 3, 3])\n",
            "layer2.0.bn2.weight torch.Size([128])\n",
            "layer2.0.bn2.bias torch.Size([128])\n",
            "layer2.0.downsample.0.weight torch.Size([128, 64, 1, 1])\n",
            "layer2.0.downsample.1.weight torch.Size([128])\n",
            "layer2.0.downsample.1.bias torch.Size([128])\n",
            "layer2.1.conv1.weight torch.Size([128, 128, 3, 3])\n",
            "layer2.1.bn1.weight torch.Size([128])\n",
            "layer2.1.bn1.bias torch.Size([128])\n",
            "layer2.1.conv2.weight torch.Size([128, 128, 3, 3])\n",
            "layer2.1.bn2.weight torch.Size([128])\n",
            "layer2.1.bn2.bias torch.Size([128])\n",
            "layer3.0.conv1.weight torch.Size([256, 128, 3, 3])\n",
            "layer3.0.bn1.weight torch.Size([256])\n",
            "layer3.0.bn1.bias torch.Size([256])\n",
            "layer3.0.conv2.weight torch.Size([256, 256, 3, 3])\n",
            "layer3.0.bn2.weight torch.Size([256])\n",
            "layer3.0.bn2.bias torch.Size([256])\n",
            "layer3.0.downsample.0.weight torch.Size([256, 128, 1, 1])\n",
            "layer3.0.downsample.1.weight torch.Size([256])\n",
            "layer3.0.downsample.1.bias torch.Size([256])\n",
            "layer3.1.conv1.weight torch.Size([256, 256, 3, 3])\n",
            "layer3.1.bn1.weight torch.Size([256])\n",
            "layer3.1.bn1.bias torch.Size([256])\n",
            "layer3.1.conv2.weight torch.Size([256, 256, 3, 3])\n",
            "layer3.1.bn2.weight torch.Size([256])\n",
            "layer3.1.bn2.bias torch.Size([256])\n",
            "layer4.0.conv1.weight torch.Size([512, 256, 3, 3])\n",
            "layer4.0.bn1.weight torch.Size([512])\n",
            "layer4.0.bn1.bias torch.Size([512])\n",
            "layer4.0.conv2.weight torch.Size([512, 512, 3, 3])\n",
            "layer4.0.bn2.weight torch.Size([512])\n",
            "layer4.0.bn2.bias torch.Size([512])\n",
            "layer4.0.downsample.0.weight torch.Size([512, 256, 1, 1])\n",
            "layer4.0.downsample.1.weight torch.Size([512])\n",
            "layer4.0.downsample.1.bias torch.Size([512])\n",
            "layer4.1.conv1.weight torch.Size([512, 512, 3, 3])\n",
            "layer4.1.bn1.weight torch.Size([512])\n",
            "layer4.1.bn1.bias torch.Size([512])\n",
            "layer4.1.conv2.weight torch.Size([512, 512, 3, 3])\n",
            "layer4.1.bn2.weight torch.Size([512])\n",
            "layer4.1.bn2.bias torch.Size([512])\n",
            "fc.weight torch.Size([10, 512])\n",
            "fc.bias torch.Size([10])\n"
          ]
        }
      ],
      "source": [
        "# freeze all gradients' update except for fc layer\n",
        "for name, param in model.named_parameters():\n",
        "    print(name, param.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "749c8985-6336-47aa-aca9-5a5c155c6223",
      "metadata": {
        "id": "749c8985-6336-47aa-aca9-5a5c155c6223"
      },
      "outputs": [],
      "source": [
        "for name, param in model.named_parameters():\n",
        "    if 'fc' not in name:\n",
        "        param.requires_grad = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "bbc1ebec-3db5-406f-a1cc-58b699257d2c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbc1ebec-3db5-406f-a1cc-58b699257d2c",
        "outputId": "f6148433-f261-42fa-b6d6-895fd57468b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar10_data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:18<00:00, 9130592.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar10_data/cifar-10-python.tar.gz to ./data/cifar10_data\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)), # resnet 224x224 cifar 30x30\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=( .5, .5, .5), std =( .5, .5, .5))\n",
        "])\n",
        "\n",
        "train_dataset = CIFAR10(root='./data/cifar10_data', train=True, download=True, transform=transform)\n",
        "val_dataset = CIFAR10(root='./data/cifar10_data', train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=1024, shuffle=True, num_workers=4)\n",
        "val_loader = DataLoader(val_dataset, batch_size=1024, shuffle=False, num_workers=4)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "3fa45381-6c6c-46d8-b899-c6b5a4e30a02",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3fa45381-6c6c-46d8-b899-c6b5a4e30a02",
        "outputId": "cf9dc6a2-33f7-4085-ca0f-7749c7067a78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "                                                           "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0: train error: 1.0383074174121933, validation error: 0.9954547107219696, validation accuracy: 0.7272361278533935\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                           "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 1: train error: 0.9509177767500585, validation error: 0.922961699962616, validation accuracy: 0.7393813788890838\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 2: train error: 0.8891460810388837, validation error: 0.8712589204311371, validation accuracy: 0.7465242326259613\n",
            "train duration  406.802 sec\n"
          ]
        }
      ],
      "source": [
        "# run on GPU\n",
        "model = model.to(device)\n",
        "\n",
        "opt = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "start = time.time()\n",
        "train_losses, val_losses, val_accuracies  = utils.learn(model, train_loader, val_loader, opt, F.cross_entropy, 3)\n",
        "end = time.time()\n",
        "train_time = end - start\n",
        "print(f'train duration {train_time: .3f} sec')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.20"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}